{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI5fM142jkr+m+VrpeTM+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/BA820/blob/main/Hands-on/04-text-mining/Topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes')).data"
      ],
      "metadata": {
        "id": "HT-7bJ0XwuSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert the text data into a TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(newsgroups)"
      ],
      "metadata": {
        "id": "8dSHI4Egw67i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Apply NMF for topic modeling\n",
        "nmf = NMF(n_components=3, random_state=42)\n",
        "W = nmf.fit_transform(X)\n",
        "H = nmf.components_"
      ],
      "metadata": {
        "id": "D4e62RmVyFtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = nmf.get_feature_names_out()"
      ],
      "metadata": {
        "id": "krv6w3JRyZCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYzh0lFlkUOE",
        "outputId": "41b7f3e5-e228-4ed1-da35-d9ef6f97c302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['don', 'people', 'just', 'think', 'like', 'time', 'know', 'good', 'right', 'government']\n",
            "['windows', 'thanks', 'drive', 'card', 'dos', 'use', 'does', 'file', 'know', 'program']\n",
            "['god', 'jesus', 'bible', 'believe', 'christ', 'christian', 'faith', 'christians', 'does', 'sin']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Print the top words for each topic\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "for i, topic in enumerate(H):\n",
        "    top_words = [feature_names[j] for j in np.argsort(topic)[:-11:-1]]\n",
        "    print(top_words)"
      ]
    }
  ]
}